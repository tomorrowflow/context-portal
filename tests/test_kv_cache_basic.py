"""
Basic functionality tests for KV cache optimization system.
Tests core tool operations and basic validation.
"""

import pytest
import asyncio
import json
import tempfile
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# Import the MCP handlers directly for testing
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from context_portal_mcp.handlers import mcp_handlers
from context_portal_mcp.db import models, database
from context_portal_mcp.core.exceptions import ContextPortalError


class TestKVCacheBasicFunctionality:
    """Test suite for basic KV cache functionality"""
    
    @pytest.fixture
    def test_workspace(self):
        """Create a temporary workspace for testing"""
        with tempfile.TemporaryDirectory() as temp_dir:
            workspace_path = Path(temp_dir) / "test_workspace"
            workspace_path.mkdir()
            yield str(workspace_path)
    
    @pytest.fixture
    def sample_product_context(self):
        """Sample product context data for testing"""
        return {
            "name": "KV Cache Test Project",
            "description": "A comprehensive test project for validating KV cache optimization functionality with sufficient content to trigger caching mechanisms",
            "goals": [
                "Validate cache performance",
                "Test content identification",
                "Verify stable context assembly"
            ],
            "architecture": "Event-driven microservices architecture with distributed caching layer",
            "technologies": ["Python", "SQLite", "FastMCP", "Ollama"],
            "requirements": "High performance context assembly with sub-100ms response times"
        }
    
    @pytest.fixture
    def sample_system_patterns(self):
        """Sample system patterns for testing"""
        return [
            {
                "name": "Repository Pattern",
                "description": "Data access abstraction layer that encapsulates the logic needed to access data sources. It centralizes common data access functionality, providing better maintainability and decoupling the infrastructure or technology used to access databases from the domain model layer.",
                "tags": ["data-access", "architecture", "pattern"]
            },
            {
                "name": "Observer Pattern",
                "description": "Behavioral design pattern that defines a subscription mechanism to notify multiple objects about any events that happen to the object they're observing. Useful for implementing distributed event handling systems.",
                "tags": ["behavioral", "events", "pattern"]
            }
        ]
    
    @pytest.fixture
    def sample_custom_data(self):
        """Sample custom data with cache hints"""
        return [
            {
                "category": "Architecture",
                "key": "database_schema",
                "value": {
                    "tables": ["users", "products", "orders", "cache_metadata"],
                    "relationships": {
                        "users_orders": "one_to_many",
                        "products_orders": "many_to_many"
                    },
                    "indexes": ["idx_users_email", "idx_products_sku", "idx_cache_hint"]
                },
                "cache_hint": True
            },
            {
                "category": "Configuration",
                "key": "api_endpoints",
                "value": {
                    "base_url": "https://api.example.com",
                    "endpoints": {
                        "users": "/api/v1/users",
                        "products": "/api/v1/products",
                        "cache": "/api/v1/cache"
                    },
                    "rate_limits": {"requests_per_minute": 1000}
                },
                "cache_hint": True
            }
        ]
    
    async def setup_test_data(self, workspace_id: str, product_context: Dict, 
                            system_patterns: List[Dict], custom_data: List[Dict]):
        """Setup test data in the workspace"""
        
        # Setup product context
        update_args = models.UpdateContextArgs(
            workspace_id=workspace_id,
            content=product_context,
            patch_content=None
        )
        mcp_handlers.handle_update_product_context(update_args)
        
        # Setup system patterns
        for pattern_data in system_patterns:
            pattern_args = models.LogSystemPatternArgs(
                workspace_id=workspace_id,
                **pattern_data
            )
            mcp_handlers.handle_log_system_pattern(pattern_args)
        
        # Setup custom data with cache hints
        for data_item in custom_data:
            custom_args = models.LogCustomDataWithCacheHintArgs(
                workspace_id=workspace_id,
                **data_item
            )
            mcp_handlers.handle_log_custom_data_with_cache_hint(custom_args)
    
    def test_get_cacheable_content_basic(self, test_workspace, sample_product_context, 
                                       sample_system_patterns, sample_custom_data):
        """Test basic get_cacheable_content functionality"""
        
        # Setup test data
        asyncio.run(self.setup_test_data(
            test_workspace, sample_product_context, 
            sample_system_patterns, sample_custom_data
        ))
        
        # Test get_cacheable_content
        args = models.GetCacheableContentArgs(
            workspace_id=test_workspace,
            content_threshold=1500
        )
        
        result = mcp_handlers.handle_get_cacheable_content(args)
        
        # Validate structure
        assert isinstance(result, list)
        assert len(result) > 0
        
        # Check for required fields in each item
        for item in result:
            assert "source" in item
            assert "priority" in item
            assert "token_estimate" in item
            assert "content" in item
            assert item["priority"] in ["high", "medium", "low"]
            assert item["token_estimate"] > 0
        
        # Verify priority ordering (high priority items should come first)
        priorities = [item["priority"] for item in result]
        priority_order = {"high": 0, "medium": 1, "low": 2}
        for i in range(len(priorities) - 1):
            assert priority_order[priorities[i]] <= priority_order[priorities[i + 1]]
    
    def test_build_stable_context_prefix_basic(self, test_workspace, sample_product_context,
                                             sample_system_patterns, sample_custom_data):
        """Test basic build_stable_context_prefix functionality"""
        
        # Setup test data
        asyncio.run(self.setup_test_data(
            test_workspace, sample_product_context,
            sample_system_patterns, sample_custom_data
        ))
        
        # Test build_stable_context_prefix
        args = models.BuildStableContextPrefixArgs(
            workspace_id=test_workspace,
            format_type="ollama_optimized"
        )
        
        result = mcp_handlers.handle_build_stable_context_prefix(args)
        
        # Validate structure
        assert "stable_prefix" in result
        assert "prefix_hash" in result
        assert "total_tokens" in result
        assert "sections" in result
        assert "format_version" in result
        assert "generated_at" in result
        
        # Validate content
        assert isinstance(result["stable_prefix"], str)
        assert len(result["stable_prefix"]) > 0
        assert len(result["prefix_hash"]) == 32  # MD5 hash length
        assert result["total_tokens"] > 0
        assert isinstance(result["sections"], list)
        assert result["format_version"] == "1.0"
        
        # Validate timestamp format
        datetime.fromisoformat(result["generated_at"].replace('Z', '+00:00'))
    
    def test_get_cache_state_valid(self, test_workspace, sample_product_context,
                                 sample_system_patterns, sample_custom_data):
        """Test get_cache_state with valid hash"""
        
        # Setup test data
        asyncio.run(self.setup_test_data(
            test_workspace, sample_product_context,
            sample_system_patterns, sample_custom_data
        ))
        
        # First build stable context to get hash
        build_args = models.BuildStableContextPrefixArgs(
            workspace_id=test_workspace
        )
        stable_result = mcp_handlers.handle_build_stable_context_prefix(build_args)
        
        # Test cache state with valid hash
        cache_args = models.GetCacheStateArgs(
            workspace_id=test_workspace,
            current_prefix_hash=stable_result["prefix_hash"]
        )
        
        result = mcp_handlers.handle_get_cache_state(cache_args)
        
        # Validate structure
        assert "cache_valid" in result
        assert "current_hash" in result
        assert "provided_hash" in result
        assert "changes_detected" in result
        assert "recommendation" in result
        assert "stable_content_size" in result
        
        # Validate content
        assert result["cache_valid"] is True
        assert result["current_hash"] == stable_result["prefix_hash"]
        assert result["provided_hash"] == stable_result["prefix_hash"]
        assert result["recommendation"] == "reuse"
        assert isinstance(result["changes_detected"], list)
        assert result["stable_content_size"] > 0
    
    def test_get_cache_state_invalid(self, test_workspace, sample_product_context,
                                   sample_system_patterns, sample_custom_data):
        """Test get_cache_state with invalid hash"""
        
        # Setup test data
        asyncio.run(self.setup_test_data(
            test_workspace, sample_product_context,
            sample_system_patterns, sample_custom_data
        ))
        
        # Test cache state with invalid hash
        cache_args = models.GetCacheStateArgs(
            workspace_id=test_workspace,
            current_prefix_hash="invalid_hash_12345"
        )
        
        result = mcp_handlers.handle_get_cache_state(cache_args)
        
        # Validate invalid state
        assert result["cache_valid"] is False
        assert result["recommendation"] == "refresh"
        assert result["provided_hash"] == "invalid_hash_12345"
        assert result["current_hash"] != "invalid_hash_12345"
    
    def test_get_dynamic_context_basic(self, test_workspace, sample_product_context):
        """Test basic get_dynamic_context functionality"""
        
        # Setup minimal test data
        update_args = models.UpdateContextArgs(
            workspace_id=test_workspace,
            content=sample_product_context,
            patch_content=None
        )
        mcp_handlers.handle_update_product_context(update_args)
        
        # Add some active context
        active_context = {
            "current_focus": "Testing KV cache functionality",
            "recent_changes": ["Added cache optimization", "Enhanced context assembly"],
            "open_issues": ["Performance validation", "Error handling"]
        }
        active_args = models.UpdateContextArgs(
            workspace_id=test_workspace,
            content=active_context,
            patch_content=None
        )
        mcp_handlers.handle_update_active_context(active_args)
        
        # Test get_dynamic_context
        args = models.GetDynamicContextArgs(
            workspace_id=test_workspace,
            query_intent="decision making process",
            context_budget=2000
        )
        
        result = mcp_handlers.handle_get_dynamic_context(args)
        
        # Validate structure
        assert "dynamic_context" in result
        assert "sections" in result
        assert "total_tokens" in result
        assert "budget_used" in result
        assert "budget_remaining" in result
        
        # Validate content
        assert isinstance(result["dynamic_context"], str)
        assert isinstance(result["sections"], list)
        assert result["total_tokens"] >= 0
        assert result["budget_used"] >= 0
        assert result["budget_remaining"] >= 0
        assert result["budget_used"] + result["budget_remaining"] == 2000
        assert result["total_tokens"] <= 2000  # Respects budget
    
    def test_log_custom_data_with_cache_hint(self, test_workspace):
        """Test log_custom_data_with_cache_hint functionality"""
        
        # Test data with explicit cache hint
        args = models.LogCustomDataWithCacheHintArgs(
            workspace_id=test_workspace,
            category="Architecture",
            key="database_design",
            value={
                "type": "relational",
                "engine": "SQLite",
                "tables": ["users", "products", "orders"],
                "optimization": "KV cache integration"
            },
            suggest_caching=None,
            cache_hint=True
        )
        
        result = mcp_handlers.handle_log_custom_data_with_cache_hint(args)
        
        # Validate structure
        assert "id" in result
        assert "category" in result
        assert "key" in result
        assert "value" in result
        assert "cache_score" in result
        assert "metadata" in result
        
        # Validate content
        assert result["category"] == "Architecture"
        assert result["key"] == "database_design"
        assert result["cache_score"] > 0
        assert result["metadata"]["cache_hint"] is True
    
    def test_log_custom_data_auto_suggest(self, test_workspace):
        """Test automatic cache suggestion for large content"""
        
        # Large content that should trigger auto-suggestion
        large_content = {
            "description": "A" * 2000,  # Large content > 1500 chars
            "details": "Comprehensive system specification with extensive documentation"
        }
        
        args = models.LogCustomDataWithCacheHintArgs(
            workspace_id=test_workspace,
            category="Specifications",
            key="system_requirements",
            value=large_content,
            suggest_caching=None,  # Let it auto-suggest
            cache_hint=None
        )
        
        result = mcp_handlers.handle_log_custom_data_with_cache_hint(args)
        
        # Should include cache suggestion
        assert "cache_suggestion" in result
        assert result["cache_suggestion"]["recommended"] is True
        assert "Large content" in result["cache_suggestion"]["reason"]
        assert result["cache_suggestion"]["cache_score"] > 0
    
    def test_initialize_ollama_session(self, test_workspace, sample_product_context):
        """Test initialize_ollama_session functionality"""
        
        # Setup minimal test data
        update_args = models.UpdateContextArgs(
            workspace_id=test_workspace,
            content=sample_product_context,
            patch_content=None
        )
        mcp_handlers.handle_update_product_context(update_args)
        
        # Test session initialization
        args = models.InitializeOllamaSessionArgs(
            workspace_id=test_workspace
        )
        
        result = mcp_handlers.handle_initialize_ollama_session(args)
        
        # Validate structure
        assert "session_initialized" in result
        assert "session_id" in result
        assert "stable_context_ready" in result
        assert "stable_context_hash" in result
        assert "stable_context_tokens" in result
        assert "cache_optimization_enabled" in result
        assert "recommendations" in result
        
        # Validate content
        assert result["session_initialized"] is True
        assert len(result["session_id"]) > 0
        assert result["stable_context_ready"] is True
        assert len(result["stable_context_hash"]) == 32
        assert result["stable_context_tokens"] > 0
        assert result["cache_optimization_enabled"] is True
        assert isinstance(result["recommendations"], list)
        assert len(result["recommendations"]) > 0
    
    def test_get_cache_performance(self, test_workspace):
        """Test get_cache_performance functionality"""
        
        # Test without session ID
        args = models.GetCachePerformanceArgs(
            workspace_id=test_workspace,
            session_id=None
        )
        
        result = mcp_handlers.handle_get_cache_performance(args)
        
        # Validate structure
        assert "cache_hits" in result
        assert "cache_misses" in result
        assert "hit_rate" in result
        assert "average_stable_tokens" in result
        assert "context_assembly_time_ms" in result
        assert "recommendations" in result
        assert "session_specific" in result
        
        # Validate content
        assert isinstance(result["cache_hits"], int)
        assert isinstance(result["cache_misses"], int)
        assert 0 <= result["hit_rate"] <= 1
        assert result["average_stable_tokens"] > 0
        assert result["context_assembly_time_ms"] > 0
        assert isinstance(result["recommendations"], list)
        assert result["session_specific"] is False
        
        # Test with session ID
        args_with_session = models.GetCachePerformanceArgs(
            workspace_id=test_workspace,
            session_id="test-session-123"
        )
        
        result_with_session = mcp_handlers.handle_get_cache_performance(args_with_session)
        assert result_with_session["session_specific"] is True
        assert result_with_session["session_id"] == "test-session-123"
    
    def test_error_handling_invalid_workspace(self):
        """Test error handling with invalid workspace"""
        
        with pytest.raises(ContextPortalError):
            args = models.GetCacheableContentArgs(
                workspace_id="/nonexistent/workspace"
            )
            mcp_handlers.handle_get_cacheable_content(args)
    
    def test_token_estimation_accuracy(self):
        """Test token estimation accuracy"""
        
        # Test various content types with realistic expectations based on actual function output
        test_cases = [
            ("Simple text", 3),  # "Simple text" = 2 words + structure = ~3 tokens
            ({"key": "value", "description": "A longer description"}, 6),  # Based on actual output: 6 tokens
            (["item1", "item2", "item3"], 5),  # Based on actual output: 5 tokens
            ({"complex": {"nested": {"structure": "with multiple levels"}}}, 5)  # Based on actual output: 5 tokens
        ]
        
        for content, expected_min_tokens in test_cases:
            tokens = mcp_handlers.estimate_tokens(content)
            print(f"Content: {str(content)[:50]}... -> {tokens} tokens (expected >= {expected_min_tokens})")
            assert tokens >= expected_min_tokens, f"Token estimate too low: {tokens} < {expected_min_tokens} for content: {content}"
            assert tokens > 0
    
    def test_cache_score_calculation(self):
        """Test cache score calculation logic"""
        
        # Test different content scenarios
        test_cases = [
            # (value, category, key, expected_min_score)
            ("A" * 3000, "Architecture", "database_schema", 50),  # Large + good category + good key
            ("Small", "Other", "random", 0),  # Small content
            ({"large": "A" * 2000}, "ProjectGlossary", "config", 60),  # Large + good category + good key
        ]
        
        for value, category, key, expected_min_score in test_cases:
            score = mcp_handlers.calculate_content_cache_score(value, category, key)
            assert score >= expected_min_score
            assert 0 <= score <= 100


class TestKVCacheEdgeCases:
    """Test edge cases and error conditions"""
    
    @pytest.fixture
    def test_workspace(self):
        """Create a temporary workspace for testing"""
        with tempfile.TemporaryDirectory() as temp_dir:
            workspace_path = Path(temp_dir) / "test_workspace"
            workspace_path.mkdir()
            yield str(workspace_path)
    
    def test_empty_workspace(self, test_workspace):
        """Test behavior with empty workspace"""
        
        args = models.GetCacheableContentArgs(workspace_id=test_workspace)
        result = mcp_handlers.handle_get_cacheable_content(args)
        
        # Should return empty or minimal results, not error
        assert isinstance(result, list)
    
    def test_very_large_content(self, test_workspace):
        """Test handling of very large content"""
        
        # Create very large content
        large_value = {"data": "A" * 50000}  # 50KB of data
        
        args = models.LogCustomDataWithCacheHintArgs(
            workspace_id=test_workspace,
            category="LargeData",
            key="massive_content",
            value=large_value,
            suggest_caching=None,
            cache_hint=True
        )
        
        # Should handle without error
        result = mcp_handlers.handle_log_custom_data_with_cache_hint(args)
        assert result["cache_score"] > 0
    
    def test_special_characters_in_content(self, test_workspace):
        """Test handling of special characters and unicode"""
        
        special_content = {
            "unicode": "æµ‹è¯•å†…å®¹ ðŸš€ Ã©mojis",
            "special_chars": "!@#$%^&*()[]{}|\\:;\"'<>?,./",
            "newlines": "Line 1\nLine 2\r\nLine 3"
        }
        
        args = models.LogCustomDataWithCacheHintArgs(
            workspace_id=test_workspace,
            category="SpecialChars",
            key="unicode_test",
            value=special_content,
            suggest_caching=None,
            cache_hint=True
        )
        
        result = mcp_handlers.handle_log_custom_data_with_cache_hint(args)
        assert result["value"] == special_content


if __name__ == "__main__":
    pytest.main([__file__, "-v"])